{"cells":[{"cell_type":"markdown","metadata":{"id":"LquOGQk0YLKf"},"source":["# Mount Drive"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18916,"status":"ok","timestamp":1667270336414,"user":{"displayName":"Michael Vanden Heuvel","userId":"01139408994714691495"},"user_tz":300},"id":"h6QJG4QfYCmr","outputId":"4d51d6ec-9a45-4e97-e8c0-489a3fc2de2c"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":283,"status":"ok","timestamp":1667274029654,"user":{"displayName":"Michael Vanden Heuvel","userId":"01139408994714691495"},"user_tz":300},"id":"S0ggZJFlYbRU"},"outputs":[],"source":["import os\n","FILE_DIR = \"example_dir/Data\"\n","dataset_dir = os.path.join(FILE_DIR, \"classes.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1667274030303,"user":{"displayName":"Michael Vanden Heuvel","userId":"01139408994714691495"},"user_tz":300},"id":"-3Z7-jP_kKtn"},"outputs":[],"source":["import pandas as pd\n","df = pd.read_csv(dataset_dir)\n","df = df.rename(columns={'Scan #': 'Scan_Number'}) #changed the name of the column because the hash symbol just wont work for the method below \n","df = df.rename(columns={'post con/non con': 'con'}) #changed the name of the column because the hash symbol just wont work for the method below "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":330,"status":"ok","timestamp":1667274042856,"user":{"displayName":"Michael Vanden Heuvel","userId":"01139408994714691495"},"user_tz":300},"id":"NPciTkNlD5WV","outputId":"477d22ae-7d0c-4ee2-b306-1e746e0aec62"},"outputs":[],"source":["shape = df.shape\n","print(f\"The dataset consists of {shape[0]} rows and {shape[1]} columns\")\n","df['Scan_Number'].value_counts()\n","# print()"]},{"cell_type":"markdown","metadata":{"id":"TBKjQLbZj3ZQ"},"source":["# Generate Columns"]},{"cell_type":"markdown","metadata":{"id":"0te2UHzePGSt"},"source":["## Remove invalid rows"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":155,"status":"ok","timestamp":1667274047326,"user":{"displayName":"Michael Vanden Heuvel","userId":"01139408994714691495"},"user_tz":300},"id":"yZk2U74Ib8i-"},"outputs":[],"source":["# Remove once dataset is fixed\n","## Temporarily remove rows that have \"#VALUE!\"\n","# df = df[df['date last imaging- diagnosis dx'] != \"#VALUE!\"]\n","df.drop(df.loc[df['date last imaging- diagnosis dx'] == \"#VALUE!\"].index, inplace=True)\n","df.drop(df.loc[df['CT surveillance interval [(AB-Y)/365]'] == \"#VALUE!\"].index, inplace=True)\n","\n","\n","# Remove Scans from patients with only one scan;\n","# cannot calculate growth with only one scan\n","df = df[df.duplicated(subset=[\"Subject ID\"], keep=False)]"]},{"cell_type":"markdown","metadata":{"id":"QXmuK99An80S"},"source":["## Create Unidimensional and Volumetric Growth Column\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1667274047486,"user":{"displayName":"Michael Vanden Heuvel","userId":"01139408994714691495"},"user_tz":300},"id":"zIfBbjWvj3oj","outputId":"6b0cc6aa-df3d-4a1e-9f8a-01d3ac3e74b1"},"outputs":[],"source":["import numpy as np\n","# Unidimensional\n","# Change: Wy-Wt / time. XB\n","df['Unidimensional Rate'] = (df['1D longest dimension (cm) last imaging'].astype(float) - df['1D longest dimension (cm) 1st imaging'].astype(float))/ df['date last imaging- diagnosis dx'].astype(float)\n","df['Unidimensional Change'] = (df['1D longest dimension (cm) last imaging'].astype(float) - df['1D longest dimension (cm) 1st imaging'].astype(float))\n","\n","# Volumentric\n","# UX across two entries)/XC\n","df[\"Volumetric\"] = df['VOLUME_ML'].astype(float).diff().shift(-1) #Change across UX and shifts value to be in row with scan 1\n","df = df[df.Scan_Number  != 2] #if the scan_number is 2 then it removes the row \n","\n","# A SettingWithCopyWarning is generated from the below code, I believe it is a false positive\n","# See more: https://stackoverflow.com/questions/20625582/how-to-deal-with-settingwithcopywarning-in-pandas\n","df['Volumetric'] = df['Volumetric']/ df[\"CT surveillance interval [(AB-Y)/365]\"].astype(float) #change in growth / time\n","\n","# # remove any patients who have NaN or infinite value (due to only having one scan)\n","# ## Replace infinity and negative infinity with NaN --> drop NaN\n","df.replace([np.inf, -np.inf], np.nan, inplace=True)\n","df = df.dropna(subset=[\"Volumetric\"], how=\"all\")\n"]},{"cell_type":"markdown","metadata":{"id":"JygTOiqKnuBa"},"source":["## Generate Categorical Data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1667274047487,"user":{"displayName":"Michael Vanden Heuvel","userId":"01139408994714691495"},"user_tz":300},"id":"dKPp-6IlnuHf","outputId":"fcda8869-66e6-4234-9e25-5111fbf28fd0"},"outputs":[],"source":["CHANGE_THRESHOLD = .5\n","RATE_THRESHOLD = .2 # Threshold in years, same for threshold of .2 or .5/yr\n","\n","df['Categorical Unidimensional Change'] = (df['Unidimensional Change'] > CHANGE_THRESHOLD).astype(int)\n","df['Categorical Unidimensional Rate'] = (df['Unidimensional Rate'] > RATE_THRESHOLD).astype(int)\n","print(sum(df['Categorical Unidimensional Rate']), len(df['Categorical Unidimensional Rate']))"]},{"cell_type":"markdown","metadata":{"id":"Zk_EAUJ0lY0_"},"source":["# Process Dataset"]},{"cell_type":"markdown","metadata":{"id":"bGoeTOEl3cn4"},"source":["## Encode Categorical Data"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":179,"status":"ok","timestamp":1667274048816,"user":{"displayName":"Michael Vanden Heuvel","userId":"01139408994714691495"},"user_tz":300},"id":"QpGi6v8F3jFM"},"outputs":[],"source":["# transform categorical features\n","categorical = ['gender', 'race', 'tnum_aml', 'laterality', 'symptoms', 'hemorrhage', 'Treated Y/N', 'path_dx', 'ethnicity', 'ts'] \n","\n","for col in df:\n","  if col in categorical:\n","    one_hot = pd.get_dummies(df[col], prefix = col)\n","    df = df.drop(col, axis = 1)\n","    df = df.join(one_hot)\n","\n","# remove 'flank pain, hematuria' combination column\n","for cell in df['symptoms_flank pain, hematuria']:\n","  if cell == '1':\n","    df['symptoms_flank pain'] = 1\n","    df['symptoms_hematuria'] = 1\n","  \n","df = df.drop('symptoms_flank pain, hematuria', axis = 1)"]},{"cell_type":"markdown","metadata":{"id":"Lu95sokmRmJ1"},"source":["## Remove Columns"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1667274049154,"user":{"displayName":"Michael Vanden Heuvel","userId":"01139408994714691495"},"user_tz":300},"id":"EA_DI2P5RnrC"},"outputs":[],"source":["# Handling columns that are renamed by pandas (due to being a duplicate column name)\n","df.drop(['Scan_Number', 'Subject ID.1', 'Specialty.1', 'Modality.1', 'Modality.2', 'comments.1', \"1D longest dimension (cm) last imaging\"], axis=1,inplace=True)\n","\n","# Remove Completely Null/Empty Columns\n","df.dropna(how='all', axis='columns', inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":257,"status":"ok","timestamp":1667274049403,"user":{"displayName":"Michael Vanden Heuvel","userId":"01139408994714691495"},"user_tz":300},"id":"RRfs1F3oMsZb"},"outputs":[],"source":["import io\n","dataset_decisions = os.path.join(FILE_DIR, \"Dataset_Decisions.csv\")\n","decisions_df = pd.read_csv(dataset_decisions)\n","\n","to_drop = []                  \n","for i in range(len(decisions_df)):\n","  if decisions_df.loc[i, \"Decision\"] == \"REMOVE\":\n","    to_drop.append(decisions_df.loc[i, \"Column Name\"])\n","\n","df.drop(columns=to_drop, axis=1, inplace=True, errors=\"ignore\")"]},{"cell_type":"markdown","metadata":{"id":"Yj2PBuD5lfub"},"source":["## Remove Rows with Missing Data"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1667274049404,"user":{"displayName":"Michael Vanden Heuvel","userId":"01139408994714691495"},"user_tz":300},"id":"RfqdTLRwlY7A"},"outputs":[],"source":["# Specified rows that are missing data to drop, does not include 2nd scan rows\n","\n","\n","### This will need to be changed to accomodate the fact that we are removing columns before this\n","# rowsToDrop = [32, 132, 167,  205, 248, 270, 285, 307, 318, 408, 425,  497, 514, 436, 453, 497, 514,546, 631, 650] \n","# df = df.drop(rowsToDrop)"]},{"cell_type":"markdown","metadata":{"id":"isZYj0d4YNf2"},"source":["# Visualize Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":840},"executionInfo":{"elapsed":222,"status":"ok","timestamp":1667274055658,"user":{"displayName":"Michael Vanden Heuvel","userId":"01139408994714691495"},"user_tz":300},"id":"XCAlgmFdYM3f","outputId":"bc82e0c7-b98c-43dc-e7b6-119d39809c3d"},"outputs":[],"source":["display(df)"]},{"cell_type":"markdown","metadata":{"id":"iZCCONp7a3OP"},"source":["## Find NaN Values"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1667274055839,"user":{"displayName":"Michael Vanden Heuvel","userId":"01139408994714691495"},"user_tz":300},"id":"i7RKdt0tuIXd","outputId":"f114cbc5-a7eb-427b-e945-1ee737c9358a"},"outputs":[],"source":["# Find Columns with Any missing Values\n","ind = {}\n","\n","for col in df:\n","  if df[col].isna().sum() > 0:\n","    ind[col] = (df[df[col].isnull()].index.tolist()) \n","\n","for k in ind.keys():\n","  missing = ind[k]\n","  n = len(missing)\n","  print(f\"{k} missing {n} values at: {missing}\")\n","  # print(f\"{k} missing {n} values\")\n","  # if n == 1:\n","    # print(f\"{k}\")\n","    # print(f\"{k} missing {missing}\")\n","\n","# tmp = \", \".join([k for k,v in ind.items() if len(v) == 1])\n","# print(tmp)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1667274055840,"user":{"displayName":"Michael Vanden Heuvel","userId":"01139408994714691495"},"user_tz":300},"id":"aU4VGc-Vu4Fj","outputId":"e5a03172-f348-47c4-8e3c-736cd1cf2269"},"outputs":[],"source":["# df=df.drop('^Unnamed')\n","print(df.shape)\n","# list(df.columns)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":157,"status":"ok","timestamp":1667274055994,"user":{"displayName":"Michael Vanden Heuvel","userId":"01139408994714691495"},"user_tz":300},"id":"Gw5QKr1Fa3eU","outputId":"172a0de0-8c2b-48d9-da97-f0fe99a0067e"},"outputs":[],"source":["rows = {}\n","ind = {} # Location of NaN values in column\n","         # Won't line up with spreadsheet because of removed rows \n","drop = []\n","\n","for col in df:\n","  if df[col].isna().sum() > 0:\n","    ind[col] = (df[df[col].isnull()].index.tolist()) \n","\n","## Drop Column\n","\n","for k in ind.keys():\n","  missing = ind[k]\n","  n = len(missing)\n","  # print(f\"{k} missing {n} values at: {missing}\")\n","  # print(f\"{k} missing {n} values\")\n","  if len(missing) > 100:\n","    print(f\"Removing column {k}, missing {n}\")\n","    drop.append(k)\n","\n","df = df.drop(drop, axis=1)\n","\n","for col in df:\n","  if df[col].isna().sum() > 0:\n","    ind[col] = (df[df[col].isnull()].index.tolist()) \n","\n","for k in ind.keys():\n","  missing = ind[k]\n","  n = len(missing)\n","  print(f\"{k} missing {n} values at: {missing}\")\n","\n","\n","## Drop Rows\n","# drop = df.iloc[[True if i > 0 else False for i in df.isnull().sum(axis=1).tolist()]]\n","# df.drop(index=drop)\n","df = df.dropna(how='any',axis=0) "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1667274055995,"user":{"displayName":"Michael Vanden Heuvel","userId":"01139408994714691495"},"user_tz":300},"id":"zB4pGJhX0lRd","outputId":"a0f63bd3-a28b-4012-d9a5-331a3370e0b9"},"outputs":[],"source":["df.shape"]},{"cell_type":"markdown","metadata":{"id":"I3dFMb-6o2rW"},"source":["# Export Modified Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":349,"status":"ok","timestamp":1667274065927,"user":{"displayName":"Michael Vanden Heuvel","userId":"01139408994714691495"},"user_tz":300},"id":"8vGYtX6FRypZ","outputId":"8cd3da45-1b94-4c43-b7bb-3c721db2aa25"},"outputs":[],"source":["df.shape"]},{"cell_type":"markdown","metadata":{"id":"v77buUMJp_1t"},"source":["## Regression Datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nx_fAs2Io5RP"},"outputs":[],"source":["# Comment out the below line to run code\n","%%script false\n","\n","import datetime\n","\n","t = datetime.timezone(datetime.timedelta(hours=-5)) # CT Timezone offset -5 from UTC (varies based on DST)\n","current_time = datetime.datetime.now(tz=t).strftime(\"%Y-%m-%d %H:%M:%S\")\n","loc = os.path.join(FILE_DIR, \"Datasets/\")\n","loc = \"'\"+loc+\"'\"\n","\n","# Full Processed csv\n","#Export current data set \n","filename = \"original_processed_\"+current_time+\".csv\"\n","df.to_csv(filename,index=False)\n","filename = \"'\"+filename+\"'\"\n","!cp {filename} {loc}\n","\n","# Volumetric Growth Dataset \n","## Post Con\n","post_vol = df.copy()\n","post_vol = post_vol[post_vol[\"con\"].str.contains(\"post\")]\n","post_vol = post_vol.drop(\"Unidimensional Rate\", axis=1)\n","post_vol = post_vol.drop(\"Unidimensional Change\", axis=1)\n","post_vol = post_vol.drop(\"con\", axis=1)\n","\n","filename = 'post_con_volumetric_'+current_time+'.csv'\n","post_vol.to_csv(filename,index=False)\n","filename = \"'\"+filename+\"'\"\n","!cp {filename} {loc}\n","\n","## Non Con\n","non_vol = df.copy()\n","non_vol = non_vol[non_vol[\"con\"].str.contains(\"non\")]\n","non_vol = non_vol.drop(labels=\"Unidimensional Rate\", axis=1)\n","non_vol = non_vol.drop(labels=\"Unidimensional Change\", axis=1)\n","non_vol = non_vol.drop(\"con\", axis=1)\n","\n","filename = 'non_con_volumetric_'+current_time+'.csv'\n","non_vol.to_csv(filename,index=False)\n","filename = \"'\"+filename+\"'\"\n","!cp {filename} {loc}\n","\n","# Unidimensional Rate Growth Dataset\n","## Post-con\n","post_uni_rate = df.copy()\n","post_uni_rate = post_uni_rate[post_uni_rate[\"con\"].str.contains(\"post\")]\n","post_uni_rate = post_uni_rate.drop(\"Volumetric\", axis=1)\n","post_uni_rate = post_uni_rate.drop(\"Unidimensional Change\", axis=1)\n","post_uni_rate = post_uni_rate.drop(\"con\", axis=1)\n","\n","filename = 'post_con_rate_unidimensional_'+current_time+'.csv'\n","post_uni_rate.to_csv(filename,index=False)\n","filename = \"'\"+filename+\"'\"\n","!cp {filename} {loc}\n","\n","## Non-con\n","non_uni_rate = df.copy()\n","non_uni_rate = non_uni_rate[non_uni_rate[\"con\"].str.contains(\"non\")]\n","non_uni_rate = non_uni_rate.drop(\"Volumetric\", axis=1)\n","non_uni_rate = non_uni_rate.drop(\"Unidimensional Change\", axis=1)\n","non_uni_rate = non_uni_rate.drop(\"con\", axis=1)\n","\n","filename = 'non_con_rate_unidimensional'+current_time+'.csv'\n","non_uni_rate.to_csv(filename,index=False)\n","filename = \"'\"+filename+\"'\"\n","!cp {filename} {loc}\n","\n","# Unidimensional Change Growth Dataset\n","## Post-con\n","post_uni_change = df.copy()\n","post_uni_change = post_uni_change[post_uni_change[\"con\"].str.contains(\"post\")]\n","post_uni_change = post_uni_change.drop(\"Volumetric\", axis=1)\n","post_uni_change = post_uni_change.drop(\"Unidimensional Rate\", axis=1)\n","post_uni_change = post_uni_change.drop(\"con\", axis=1)\n","\n","filename = 'post_con_change_unidimensional_'+current_time+'.csv'\n","post_uni_change.to_csv(filename,index=False)\n","filename = \"'\"+filename+\"'\"\n","!cp {filename} {loc}\n","\n","## Non-con\n","non_uni_change = df.copy()\n","non_uni_change = non_uni_change[non_uni_change[\"con\"].str.contains(\"non\")]\n","non_uni_change = non_uni_change.drop(\"Volumetric\", axis=1)\n","non_uni_change = non_uni_change.drop(\"Unidimensional Rate\", axis=1)\n","non_uni_change = non_uni_change.drop(\"con\", axis=1)\n","\n","filename = 'non_con_change_unidimensional_'+current_time+'.csv'\n","non_uni_change.to_csv(filename,index=False)\n","filename = \"'\"+filename+\"'\"\n","!cp {filename} {loc}\n","print(\"Files Copied!\")"]},{"cell_type":"markdown","metadata":{"id":"Bqfx2I3QqDBO"},"source":["## Classification Based Datasets (Includes regression as subcategory of classification)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":681,"status":"ok","timestamp":1649909696404,"user":{"displayName":"Michael Vanden Heuvel","userId":"01139408994714691495"},"user_tz":300},"id":"LetXu2YAqDHU","outputId":"768ed2ec-d29d-4ecf-8595-8fb98e45d6d9"},"outputs":[],"source":["# Comment out the below line to run code\n","# %%script false\n","\n","import datetime\n","\n","t = datetime.timezone(datetime.timedelta(hours=-5)) # CT Timezone offset -5 from UTC (varies based on DST)\n","current_time = datetime.datetime.now(tz=t).strftime(\"%Y-%m-%d %H:%M:%S\")\n","loc = os.path.join(FILE_DIR, \"Datasets/\")\n","loc = \"'\"+loc+\"'\"\n","\n","## Datasets to output\n","### Post con absolute change classification\n","### Post con rate classification\n","### Post con change threshold (regression)\n","### Post con rate threshold (regression)\n","\n","## Datasets to output\n","### Post con absolute change classification\n","post_uni_change_class = df.copy()\n","post_uni_change_class = post_uni_change_class[post_uni_change_class[\"con\"].str.contains(\"post\")]\n","post_uni_change_class = post_uni_change_class.drop(\"Volumetric\", axis=1)\n","post_uni_change_class = post_uni_change_class.drop(\"Unidimensional Change\", axis=1)\n","post_uni_change_class = post_uni_change_class.drop(\"Unidimensional Rate\", axis=1)\n","post_uni_change_class = post_uni_change_class.drop(\"Categorical Unidimensional Rate\", axis=1)\n","post_uni_change_class = post_uni_change_class.drop(\"con\", axis=1)\n","\n","filename = 'post_con_change_classification_'+current_time+'.csv'\n","post_uni_change_class.to_csv(filename,index=False)\n","filename = \"'\"+filename+\"'\"\n","!cp {filename} {loc}\n","\n","### Post con rate classification\n","post_uni_rate_class = df.copy()\n","post_uni_rate_class = post_uni_rate_class[post_uni_rate_class[\"con\"].str.contains(\"post\")]\n","post_uni_rate_class = post_uni_rate_class.drop(\"Volumetric\", axis=1)\n","post_uni_rate_class = post_uni_rate_class.drop(\"Unidimensional Change\", axis=1)\n","post_uni_rate_class = post_uni_rate_class.drop(\"Unidimensional Rate\", axis=1)\n","post_uni_rate_class = post_uni_rate_class.drop(\"Categorical Unidimensional Change\", axis=1)\n","post_uni_rate_class = post_uni_rate_class.drop(\"con\", axis=1)\n","\n","filename = 'post_con_rate_classification_'+current_time+'.csv'\n","post_uni_rate_class.to_csv(filename,index=False)\n","filename = \"'\"+filename+\"'\"\n","!cp {filename} {loc}\n","\n","\n","### New Regression Datasets (above threshold)\n","### Post con change threshold (regression)\n","post_uni_change_regression = df.copy()\n","post_uni_change_regression = post_uni_change_regression[post_uni_change_regression[\"con\"].str.contains(\"post\")]\n","post_uni_change_regression = post_uni_change_regression.drop(\"Volumetric\", axis=1)\n","# post_uni_change_regression = post_uni_change_regression.drop(\"Unidimensional Change\", axis=1) # this is what you are predicting\n","post_uni_change_regression = post_uni_change_regression.drop(\"Unidimensional Rate\", axis=1)\n","post_uni_change_regression = post_uni_change_regression[post_uni_change_regression[\"Categorical Unidimensional Change\"] == 1]\n","post_uni_change_regression = post_uni_change_regression.drop(\"Categorical Unidimensional Change\", axis=1)\n","post_uni_change_regression = post_uni_change_regression.drop(\"con\", axis=1)\n","\n","filename = 'post_con_change_regression_'+current_time+'.csv'\n","post_uni_change_regression.to_csv(filename,index=False)\n","filename = \"'\"+filename+\"'\"\n","!cp {filename} {loc}\n","\n","### Post con rate threshold (regression)\n","post_uni_rate_regression = df.copy()\n","post_uni_rate_regression = post_uni_rate_regression[post_uni_rate_regression[\"con\"].str.contains(\"post\")]\n","post_uni_rate_regression = post_uni_rate_regression.drop(\"Volumetric\", axis=1)\n","post_uni_rate_regression = post_uni_rate_regression.drop(\"Unidimensional Change\", axis=1)\n","# post_uni_rate_regression = post_uni_rate_regression.drop(\"Unidimensional Rate\", axis=1) # this is what you are predicting\n","post_uni_rate_regression = post_uni_rate_regression[post_uni_rate_regression[\"Categorical Unidimensional Rate\"] == 1]\n","post_uni_rate_regression = post_uni_rate_regression.drop(\"Categorical Unidimensional Rate\", axis=1)\n","post_uni_rate_regression = post_uni_rate_regression.drop(\"con\", axis=1)\n","\n","filename = 'post_con_rate_regression_'+current_time+'.csv'\n","post_uni_rate_regression.to_csv(filename,index=False)\n","filename = \"'\"+filename+\"'\"\n","!cp {filename} {loc}\n","\n","\n","print(\"Files Copied!\")"]}],"metadata":{"colab":{"collapsed_sections":["TBKjQLbZj3ZQ","QXmuK99An80S","Zk_EAUJ0lY0_","bGoeTOEl3cn4","v77buUMJp_1t"],"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
